\documentclass[11pt]{article}
\usepackage[margin=1.5in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[hyphens]{url}
\newcommand{\eat}[1]{}

\title{Developer's Guide for Libra 1.1.2c}
\author{Daniel Lowd $<$lowd@cs.uoregon.edu$>$\\
Amirmohammad Rooshenas $<$pedram@cs.uoregon.edu$>$}

\begin{document}
\maketitle

\section{Introduction}

Libra's code was written to be efficient, concise, and have few
external dependencies.  This document describes the design of the
Libra toolkit and how to use or extend its functionality.

\section{Implementation}

Libra is implemented in OCaml, a programming language in the ML family
that supports procedural, functional, and object-oriented programming
paradigms.  Libra was developed using OCaml 4.02, and may not be fully
compatible with earlier versions.

\subsection{Why OCaml?}

Programs written in OCaml can be compiled to either byte code or
native code.  Native code performance is much faster than Python and
often competitive with C++.  This speed is important when implementing
algorithms that could run for hours or days.  OCaml is statically
typed with automatic type inference, which leads to programs that are
much more concise and easier to refactor than similar programs written
in Java and C++, and safer than programs written in Python.  OCaml has
a good foreign function interface for connecting to C libraries, such
as expat, lbfgs, and our own optimized pseudo-likelihood computation
code.

As an experiment, we compared the speed of the Libra Gibbs sampler to
a similar one that we wrote in C++ some years ago.  To our surprise,
the OCaml implementation was actually 23\% faster!  Theoretically, a
carefully optimized C++ program should almost never be slower than one
in OCaml.  In practice, however, working in OCaml can make it easier
to optimize code, leading to a faster implementation given limited
development time.

\subsection{Programming Style}

Libra uses both procedural and functional paradigms.  Functional
paradigms can lead to faster development and more concise code, but
procedural methods are often necessary for obtaining faster code that
uses less memory, making some algorithms easier to implement.  The
overriding goal in Libra is practicality, not purity.  Hence, mutation
is used fairly heavily.

We have chosen not to use the object-oriented features of OCaml.
(OCaml's variant types are typically the preferred approach when
inheritance is not required.)  Named and optional parameters are an
OCaml feature that we are not currently using, but may use at some
point in the future.

\section{Organization and Compilation}

All source code is in subdirectories of the {\tt src/} directory.
Each subdirectory is devoted to either a library (e.g., {\bf data},
{\bf bn}, etc.) or one or more commands (e.g., {\bf acbn}, {\bf util},
{\bf inference}, etc.).

The build process is managed by OASIS.  The build
configuration is specified by the {\tt \_oasis} configuration file.
OASIS uses this specification to generate all files for the build
process, including {\tt Makefile}, {\tt configure}, {\tt setup.ml},
{\tt myocamlbuild.ml}, {\tt \_tags}, and more.  If you have OASIS
installed, you can edit the configuration file and run {\tt oasis
setup} to regenerate all build files.  The source distribution also
includes pre-generated build files so that Libra can be built without
OASIS.  See the OASIS manual for more information:
\url{http://oasis.forge.ocamlcore.org/MANUAL.html}.

The generated Makefile supports the standard build commands:
\begin{itemize}
\item {\tt make}: Build all executables.  The resulting binaries are
automatically copied to {\tt bin/} by the {\tt
script/\textunderscore{}move\textunderscore{}binaries.sh} script.

\item {\tt make doc}: Build HTML API documentation, generated with
{\tt ocamldoc}.  The documentation is placed in {\tt doc/html/}.

\item {\tt make clean}: Remove all files generated by the build
process.

\item {\tt make distclean}: Remove all files generated by the build
process or configuration.

\item {\tt make install}: Copy binaries and PDF documentation to the
appropriate installation directories.  These directories can be
modified using the {\tt configure} script.  This command relies on the
{\tt script/\textunderscore{}install.sh} script.

\item {\tt make uninstall}: Remove binaries and PDF documentation from
the appropriate installation directories.  These directories can be
modified using the {\tt configure} script.  This command relies on the
{\tt script/\textunderscore{}uninstall.sh} script.
\end{itemize}

\section{Supporting Libraries}

The toolkit employs nine libraries: {\bf ext}, extensions to the
standard library; {\bf data}, reading and writing of examples; {\bf
mn}, Markov networks and log-linear models; {\bf bn}, Bayesian
networks and dependency networks; {\bf circuit}, arithmetic circuits;
{\bf spn}, sum-product networks; {\bf pll}, optimized computation of
pseudo-likelihood and its gradient; and {\bf lbfgs}, the
limited-memory BFGS optimization algorithm.  

The {\bf lbfgs} library consists of OCaml bindings to the C library
{\tt libLBFGS} by Naoaki Okazaki, based on the original FORTRAN
implementation by Jorge Nocedal.  {\tt libLBFGS} is released under the
MIT open-source license and included in the Libra distribution for
convenience.  This library also supports L1 regularization using the
Orthant-Wise Limited-memory Quasi-Newton (OWL-QN) algorithm.  For more
information, see: \url{http://www.chokkan.org/software/liblbfgs/}.

Libra depends on one external library, {\tt ocaml-expat}.  Expat was
written by James Clarke, and the OCaml bindings in the {\tt
ocaml-expat} library were developed by Maas-Maarten Zeeman.  {\tt
ocaml-expat} is available as an OPAM package.

We describe the libraries that were developed internally to Libra in
more detail below.  For full documentation of each library's
interface, see the automatically generated API reference available in
the {\tt doc/html} subdirectory of Libra.

\subsection{Ext Library}

The {\bf ext} library includes miscellaneous utility functions,
extensions to the OCaml standard library (including List and Array),
and two utility modules, Timer and Heap (priority queue implemented as
a binary heap).  If you wish to add general-purpose functions, such as
an {\tt Array.map4} function that performs a {\tt map} over four lists
at once, {\bf ext} is the place to implement it.  {\bf ext} also
includes common arguments, shared mechanisms for working with log
files, probability distributions, and more.

\subsection{Data Library}

The {\bf data} library includes facilities for reading discrete-valued
data points from a file, writing them to output streams, reading in
variable schemas (represented as an array of variable dimensions),
checking that a data point is valid according to a given schema (i.e.,
having the correct length and a legal value in each dimension), and
reading and writing lists of marginal distributions.  Future
functionality for this library could include support for other file
formats, such as ARFF, or more general-purpose manipulation methods.

\subsection{Mn Library}

The {\bf mn} library reads, writes, and represents Markov networks
with factors represented as tables, trees, sets of features, or
individual features.  A dummy ``constant'' factor is also allowed.
Most of the content is in {\tt factor.ml}, which defines the different
types of factors, how to get the factor value for different
configurations, how to convert among different types of factors, how
to simplify them given evidence, and how to write them to a file or
stream.

File I/O for the {\tt .mn} format is handled by {\tt mnLexer.mll} and
{\tt mnParser.mly}.  The UAI file format is handled by {\tt
uaiFormat.ml}.  See these files for examples if you wish to add more
file formats. 

Some preliminary framework is also present for tied weights, but it is
not currently being used.

\subsection{Bn Library}

The {\bf bn} library reads, writes, and represents Bayesian networks
(BNs) and dependency networks (DNs) with conditional probability
distributions (CPDs) that are trees, tables, or arbitrary sets of
factors.  The basic type is defined in {\tt bnType.ml}, which is then
included by {\tt bn.ml}.  Files {\tt bifFile.ml}, {\tt xmodFile.ml},
and {\tt cnFile.ml} support reading and writing Bayesian networks in
the Bayesian interchange format (BIF), WinMine's .xmod format, and
Libra's .bn format, respectively.  The reason for the split between
{\tt bnType.ml} and {\tt bn.ml} is to avoid circular dependencies,
since the file formats depend on the Bayesian network data type, and
we wish to make these file formats available through the single
interface of {\tt bn.ml}.

Methods for accessing a BN include computing the conditional
probability of a node given a state vector that specifies the values
of its parents, computing the probability of a node given its Markov
blanket, converting to a Markov network, generating a sample from an
empty network (i.e., one with no evidence), and more.  Methods for
setting CPDs are provided, but are somewhat limited.  

DNs are differentiated by the {\tt acyclic} flag, which is false for
DNs and true for BNs.  This mainly affects how Markov blanket
probabilities are computed, which only depend on the parents in a DN.

Future functionality could include better interfaces for manipulating
the structure and parameters of a BN, support for other file formats
(such as the XML-based BIF format), and better error handling.

\subsection{Circuit Library}

The {\bf circuit} library reads, writes, and represents arithmetic
circuits.  An arithmetic circuit is a directed, acyclic graph in which
each interior node is a sum or product of its children, and each leaf
is an indicator variable or numeric constant.  Arithmetic circuits can
be used to represent any log linear model.  Arbitrary marginal and
conditional probabilities can be computed in linear time in the size
of the circuit, but the circuit may have exponential size in the
original model.  See Darwiche (2003) for more information on
arithmetic circuits.  Arithmetic circuits are very closely related to
sum-product networks described by Poon and Domingos (2011);
see Rooshenas and Lowd (2014) for more details on the relationship
between the two representations.

The file {\tt node.ml} defines a data type representing a
node in an arithmetic circuit, which is one of the following types:
\begin{itemize}
\item {\tt TimesNode}: the product of its children
\item {\tt PlusNode}: the sum of its children
\item {\tt VarNode}($\mbox{var}$, $\mbox{value}$): the indicator variable
which is 1 if the specified variable can take on a particular value and 
0 otherwise
\item {\tt ConstNode}($w$): a constant with value $e^w$
\item {\tt DummyNode}: a placeholder for representing a ``null'' node
\end{itemize}
It includes basic facilities for constructing, evaluating, and even
iterating over a graph of nodes.  It also defines sets and hash maps of
nodes.

All node definitions are included by {\tt circuit.ml}, which defines
the circuit data type and methods for constructing circuits and using
them for inference.

\subsection{Spn Library}

The {\bf spn} library reads, writes, and represents sum-product networks (SPNs). 
It has also been used for representing mixture of trees. 
Each node in an SPN defines a distribution as one of the following:
\begin{itemize}
\item {\tt TimesNode}: the product of the distributions represented by its children.
\item {\tt PluseNode}: the mixture of the distributions represented by its children.
\item {\tt LeafNode}: a uni-variate or multi-variate distribution.
\end{itemize} 
The SPN library provides a set of methods for creating SPN structures, as well as 
horizontal (sample) and vertical (variable) partitioning methods for learning 
SPN structures. These partitioning methods have been used in 
Gens and Domingos (2013) and Rooshenas and Lowd (2014). 

The definition and methods are included in {\tt spn.ml}. 

\subsection{Pll Library}

The {\bf pll} library performs efficient computation of
pseudo-likelihood and its gradient, given a Markov network represented
as a set of weighted conjunctive features.  It includes
implementations in both OCaml and C.  The C implementations are
recommended, since they have been more heavily optimized.  See the
code for {\tt mscore} and {\tt mnlearnw} for example usage.

\section{Modifying Libraries}

If you wish to add an algorithm to Libra and you need additional
functions in one of the libraries, you are encouraged to add this
functionality.  If you modify a library's interface as well, then you
must modify the interface ({\tt .mli} file) accordingly.  You can use
the available automated testing, to make sure that the new changes do
not break some other parts of the toolkit.

\section{Automated Testing}

A few automated tests are available in the {\tt test/} directory.
To run all of them, use the {\tt runall.sh} script:
\begin{verbatim}
  cd test
  ./runall.sh
\end{verbatim}

Some of these tests are sensitive to differences in the random number
generator or floating point arithmetic.  These ``fragile'' tests are
run at the end of the {\tt runall.sh} script.  Failure of a fragile
test does not necessarily indicate broken code, just a difference of
some kind.  When one or more tests fail, you can compare the generated
output files to the test files.

Each subdirectory of {\tt test/} contains tests pertaining to the
programs from the corresponding subdirectory of {\tt src/}.  For
instance, {\tt test/util} contains tests for {\tt mscore} and {\tt
bnsample}.  Tests within a single directory are run using the {\tt
run.sh} script.  For example, to run just the {\tt util} tests,
execute the following:
\begin{verbatim}
  cd test/util
  ./run.sh
\end{verbatim}
Fragile tests are run by the {\tt run-fragile.sh} script, if present.

Note that these are not unit tests. They test the complete
functionality of programs, not the individual functions within them.
Their main use at this point is to make it easier to identify when a
modification has resulted in broken functionality.  

\end{document}
